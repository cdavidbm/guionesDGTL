# Guion 3: Interactividad con Inteligencia Artificial Generativa

---

Hola de nuevo a todos y todas. En nuestro video anterior estuvimos hablando sobre el UX narrativo y cómo la interactividad emocional nos permite crear conexiones genuinas con las personas a través del diseño digital. Bueno, hoy vamos a dar ese salto que les prometí hacia algo que está transformando radicalmente el panorama de la interactividad: la inteligencia artificial generativa. Y les adelanto que esto es fascinante, porque ya no estamos hablando solamente de máquinas que responden a comandos predefinidos... estamos hablando de máquinas que conversan, que crean, que aprenden junto contigo.

Entonces, ¿qué es exactamente la interactividad generativa? Miren, la IA generativa transforma la experiencia digital en un diálogo constante y dinámico. Ya no se trata de que el usuario presione un botón y reciba una respuesta fija que alguien programó hace meses. No, ahora podemos crear textos completamente nuevos, generar imágenes que nunca antes existieron, producir sonidos, incluso crear personajes virtuales... todo en tiempo real y adaptándose específicamente a cada usuario. Es como tener un colaborador creativo que nunca se cansa y que puede reinventarse en cada interacción.

Y aquí quiero detenerme un momento porque esto marca un cambio profundo en cómo entendemos la interactividad. Cuando diseñamos flujos no lineales en el primer video, estábamos creando caminos múltiples pero predefinidos. El usuario elegía entre opciones que nosotros habíamos diseñado previamente. Cuando trabajamos el diseño emocional en el segundo video, creamos interfaces que respondían a las acciones del usuario con cambios de color, sonido, animaciones... pero también predefinidos. Ahora, con la IA generativa, entramos a un territorio completamente distinto: las respuestas se crean en el momento, son únicas para cada interacción, pueden adaptarse a contextos que nunca anticipamos.

Hay varias categorías de IA generativa que podemos usar, y cada una abre posibilidades diferentes. Están los modelos de lenguaje, que generan texto. Los modelos de imagen, que crean visuales a partir de descripciones. Los modelos de voz, que sintetizan audio realista. Los modelos de video, que pueden generar o modificar contenido audiovisual. Y luego están los modelos multimodales, que combinan varias de estas capacidades. Cada tipo tiene sus aplicaciones específicas en el diseño de experiencias interactivas.

Empecemos por los modelos de lenguaje, que probablemente sean los más conocidos y accesibles en este momento. GPT, de OpenAI, es el más popular, pero también están Claude de Anthropic, Gemini de Google, y varias alternativas de código abierto como Llama de Meta. Estos modelos pueden mantener conversaciones coherentes, responder preguntas con información contextual, generar textos creativos, traducir, resumir, explicar conceptos complejos de formas sencillas. La versatilidad es enorme.

Imaginen que queremos crear un chatbot educativo que acompañe a estudiantes en un proceso de aprendizaje sobre memoria histórica. Con GPT o una plataforma como Character.AI, que está específicamente diseñada para crear personajes conversacionales, podemos diseñar un asistente virtual que no solo responda preguntas predefinidas, sino que realmente converse con el estudiante. Puede adaptarse al nivel de conocimiento que detecta en las respuestas del estudiante, hacer preguntas de seguimiento inteligentes que profundicen en aspectos específicos, ofrecer ejemplos personalizados según los intereses que vaya identificando en la conversación.

Por ejemplo, si un estudiante pregunta sobre el conflicto armado en Colombia y menciona que es de una región específica, el chatbot puede conectar esa información general con historias o eventos particulares de esa región. Puede ajustar el tono de la conversación, ser más formal o más cercano según cómo responde el estudiante. Puede detectar si alguien está confundido y replantear la explicación de otra manera. Esa es interactividad generativa: cada conversación es única, se construye en el momento, responde al usuario específico que está interactuando.

Ahora pasemos a los modelos de generación de imágenes. Herramientas como Midjourney, DALL-E, Leonardo.ai o Stable Diffusion pueden producir arte visual completamente nuevo a partir de descripciones textuales que llamamos prompts. Esto abre posibilidades creativas enormes para experiencias interactivas visuales.

Pensemos en un caso concreto: queremos crear una exposición virtual sobre biodiversidad. Con estas herramientas podemos generar ilustraciones únicas de ecosistemas según las preferencias del visitante. El usuario entra y elige qué tipo de ecosistema quiere explorar: bosques tropicales, páramos, humedales, ecosistemas marinos. Según su elección, la IA genera visualizaciones específicas de ese bioma, con especies características, interacciones ecológicas, paisajes particulares. Si otro visitante prefiere ecosistemas marinos, la experiencia visual se transforma completamente. Y todo esto sucede en tiempo real, adaptándose continuamente.

Lo interesante es que podemos combinar esto con el diseño emocional que vimos en el video anterior. Podemos pedirle a la IA que genere imágenes con tonos específicos: si queremos transmitir urgencia sobre conservación, podemos generar visuales más dramáticos. Si queremos celebrar la biodiversidad, visuales más vibrantes y esperanzadores. El prompt que usamos para generar la imagen no solo describe qué mostrar, sino cómo hacerlo emocionalmente.

Y luego están herramientas como RunwayML o D-ID que trabajan con contenido audiovisual generativo. RunwayML puede generar videos cortos, modificar videos existentes, hacer efectos que antes requerían equipos de producción profesional. D-ID es fascinante porque puede crear avatares digitales que hablan, con sincronización labial realista, a partir de una foto estática y un audio. Esto tiene aplicaciones increíbles para crear presentadores virtuales, narradores de historias, guías de museo que pueden hablar en múltiples idiomas.

Imaginen una experiencia de memoria histórica donde líderes comunitarios que ya no están con nosotros puedan "contar" sus historias a través de avatares digitales generados a partir de fotografías antiguas. Obviamente esto tiene implicaciones éticas profundas que debemos manejar con extremo cuidado y siempre con el consentimiento de las familias y comunidades, pero la posibilidad técnica existe.

Character.AI merece mención especial porque permite crear personajes con personalidades, tonos, conocimientos y estilos de conversación específicos. Puedes diseñar un personaje que sea un educador paciente que explica conceptos difíciles con metáforas, o un mentor motivacional que celebra cada logro pequeño, o un co-explorador curioso que hace preguntas junto contigo. Cada personaje mantiene coherencia en sus respuestas, recuerda conversaciones anteriores, desarrolla una relación con el usuario a lo largo del tiempo.

Pero aquí viene algo crucial, y esto quiero que quede absolutamente claro: la IA debe usarse con propósito ético y educativo. No se trata de reemplazar voces humanas, sino de amplificarlas. La inteligencia artificial es un puente entre la creatividad humana y la tecnología responsable, no un sustituto de la experiencia, la sensibilidad o el juicio humano.

Déjenme ser muy específico sobre esto porque es fundamental en nuestra perspectiva de educomunicación para la paz. Cuando usamos IA para crear experiencias interactivas sobre temas sociales, sobre memoria, sobre paz, sobre derechos humanos, tenemos que preguntarnos constantemente: ¿estamos usando esta tecnología para facilitar que voces reales sean escuchadas, o la estamos usando para crear narrativas artificiales que reemplazan las auténticas?

Les comparto un ejemplo concreto de aplicación ética. Pensemos en una exposición virtual sobre historias de paz en comunidades rurales. Podríamos diseñar un asistente de IA que guíe a los visitantes por diferentes testimonios y recursos. Este asistente puede hacer varias cosas valiosas: puede ayudar a navegar entre contenidos, sugiriendo rutas según los intereses del visitante. Puede hacer conexiones entre temas, señalando cómo la historia de un líder comunitario se relaciona con una iniciativa específica o un lugar particular. Puede responder dudas contextuales, explicando términos específicos, aclarando fechas, dando información de fondo.

Pero, y esto es clave, el asistente no inventa testimonios. No genera historias falsas de personas que no existen. No modifica o embellece las narrativas reales. Los testimonios verdaderos, las historias auténticas, las voces originales permanecen intactas. La IA facilita el acceso, personaliza la experiencia, crea conexiones, responde preguntas... pero no suplanta lo humano. Esa es la diferencia ética fundamental entre usar IA como herramienta de amplificación versus usarla para reemplazar o distorsionar lo genuino.

También es importante que hablemos de las limitaciones y sesgos de estas herramientas. La IA generativa aprende de datos existentes, de textos e imágenes que ya están en internet, en bases de datos, en archivos digitales. Y esos datos muchas veces reflejan desigualdades, estereotipos, perspectivas limitadas, prejuicios históricos. Si la mayor parte de los datos de entrenamiento provienen de contextos occidentales, la IA tendrá sesgos hacia esas perspectivas. Si los datos incluyen estereotipos sobre género, etnia, clase social, la IA puede reproducir y hasta amplificar esos estereotipos.

Por ejemplo, si le pedimos a un generador de imágenes que nos muestre "un líder comunitario", probablemente generará un hombre adulto, porque esa es la representación más común en los datos con los que fue entrenado. Si le pedimos "una persona científica", probablemente generará un hombre blanco de mediana edad. Estos sesgos no son neutrales, tienen consecuencias reales en cómo representamos el mundo y a quién hacemos visible o invisible.

Por eso, cuando diseñamos experiencias interactivas con IA, debemos ser críticos, revisar constantemente los resultados, ajustar los prompts con intención, ser específicos sobre diversidad y representación, y sobre todo mantener una supervisión humana consciente y continua. No podemos simplemente generar contenido con IA y publicarlo sin revisar críticamente qué perspectivas está privilegiando, qué voces está excluyendo, qué estereotipos puede estar reforzando.

Y aquí hay algo que quiero compartirles desde mi propia experiencia trabajando con estas herramientas. Al principio es fácil fascinarse con las capacidades técnicas y olvidar las preguntas éticas. Generas una imagen impresionante y te emocionas con lo que la tecnología puede hacer. Pero luego tienes que detenerte y preguntarte: ¿esta imagen representa con justicia a las personas o comunidades que dice mostrar? ¿Está reproduciendo estereotipos? ¿A quién estoy haciendo visible y a quién invisible con esta representación? Esas preguntas incómodas son las que nos mantienen en el terreno ético.

Bueno, ahora les toca a ustedes experimentar, y quiero que lo hagan con esa conciencia ética presente. La tarea que les propongo es esta: creen una pequeña interacción con IA generativa. Puede ser un texto generado que responda a una pregunta relevante de su audiencia, puede ser una imagen que visualice un concepto que quieran comunicar, o puede ser un diálogo breve con un chatbot que diseñen para un propósito educativo específico.

Usen las herramientas que mencionamos. Para texto, pueden probar ChatGPT, Claude o Character.AI. Para imágenes, Leonardo.ai tiene una versión gratuita muy generosa, igual que Bing Image Creator que usa DALL-E. Para crear avatares que hablan, D-ID tiene un plan gratuito limitado pero funcional para experimentar. Exploren, jueguen con las posibilidades, vean qué pueden crear.

Y mientras lo hacen, mantengan estas preguntas en mente constantemente: ¿esto amplifica voces humanas o las reemplaza? ¿Estoy usando la IA para crear conexiones genuinas o solo para automatizar? ¿Los resultados que estoy obteniendo son éticamente responsables o reproducen sesgos? ¿Cómo puedo ajustar mis prompts para obtener resultados más diversos, más justos, más representativos? Esas reflexiones son tan importantes como el resultado técnico.

Entonces, recapitulando lo que hemos visto hoy: la IA generativa abre caminos fascinantes para contar historias vivas, adaptativas y personalizadas. Nos permite crear experiencias interactivas que evolucionan con cada usuario, que se generan en tiempo real, que pueden adaptarse a contextos y necesidades específicas que nunca anticipamos. Conocimos diferentes tipos de IA generativa, desde modelos de lenguaje hasta generadores de imagen y video. Vimos herramientas concretas y casos de aplicación. Y, crucialmente, reflexionamos sobre las dimensiones éticas: cómo usar esta potencia tecnológica siempre al servicio de propósitos educativos, de amplificación de voces genuinas, de construcción de paz.

Pero toda esta potencia tecnológica que hemos explorado, desde los flujos no lineales hasta el diseño emocional y ahora la IA generativa, viene acompañada de responsabilidades enormes. En el siguiente video vamos a abordar precisamente eso: la ética de la interactividad. Vamos a profundizar en temas que ya hemos tocado brevemente pero que merecen atención completa: la protección de datos, el consentimiento informado, los límites que debemos establecer frente a la manipulación algorítmica, cómo garantizar que nuestras experiencias interactivas respeten la autonomía y dignidad de las personas. Porque la tecnología sin ética no construye paz, puede de hecho hacer lo contrario.

Esto fue un video de Academia del programa Digitalia, Educomunicación para la Paz.

---

**Duración aproximada: 10 minutos**
